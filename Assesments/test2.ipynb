{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27f5614b",
   "metadata": {},
   "source": [
    "# Section A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abad0ad",
   "metadata": {},
   "source": [
    "Q1 Solution 1: &emsp;&emsp;&emsp; Formula:  =[@Returned]*-1<br>\n",
    "Q1 Solution 2: &emsp;&emsp;&emsp; Drag ‘Store’ in rows. Drag ‘Net Return’ in values. <br>\n",
    "Q1 Solution 3: &emsp;&emsp;&emsp; Filter the table to keep only ‘NA’ values in Returned col. Replace values in table with 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93801535",
   "metadata": {},
   "source": [
    "Q2 Solution 1: &emsp;&emsp;&emsp; Average skill score per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91882e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch\n",
      "B1    85.0\n",
      "B2    83.0\n",
      "B3    90.0\n",
      "Name: DS_Score, dtype: float64\n",
      "Batch\n",
      "B1    77.5\n",
      "B2    82.0\n",
      "B3    88.0\n",
      "Name: Viz_Score, dtype: float64\n",
      "Batch\n",
      "B1    70.0\n",
      "B2    80.5\n",
      "B3    92.0\n",
      "Name: SQL_Score, dtype: float64\n",
      "\n",
      "Mean of B1 77.5\n",
      "Mean of B2 81.83333333333333\n",
      "Mean of B3 90.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_31288\\839228853.py:17: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(\"\\nMean of B1\", (avg1 [0]+avg2[0]+avg3[0])/3)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_31288\\839228853.py:18: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(\"Mean of B2\", (avg1 [1]+avg2[1]+avg3[1])/3)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_31288\\839228853.py:19: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(\"Mean of B3\", (avg1 [2]+avg2[2]+avg3[2])/3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {\n",
    "'CandID': ['C1', 'C2', 'C3', 'C4', 'C5'],\n",
    "'Batch': ['B1', 'B1', 'B2', 'B2', 'B3'],\n",
    "'DS_Score': [85, None, 78, 88, 90],\n",
    "'Viz_Score': [80, 75, 82, None, 88],\n",
    "'SQL_Score': [None, 70, 76, 85, 92]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df\n",
    "avg1 = df.groupby('Batch') ['DS_Score'].mean()\n",
    "avg2 = df.groupby('Batch') ['Viz_Score'].mean()\n",
    "avg3 = df.groupby('Batch') ['SQL_Score'].mean()\n",
    "print(avg1)\n",
    "print(avg2)\n",
    "print(avg3)\n",
    "print(\"\\nMean of B1\", (avg1 [0]+avg2[0]+avg3[0])/3)\n",
    "print(\"Mean of B2\", (avg1 [1]+avg2[1]+avg3[1])/3)\n",
    "print(\"Mean of B3\", (avg1 [2]+avg2[2]+avg3[2])/3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46c4eba",
   "metadata": {},
   "source": [
    "Q2 Solution 2: &emsp;&emsp;&emsp; CandID with max score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "np.float64(270.0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:413\u001b[39m, in \u001b[36mRangeIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_range\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[31mValueError\u001b[39m: 270 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mTotal_score\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mDS_Score\u001b[39m\u001b[33m'\u001b[39m].fillna(\u001b[32m0\u001b[39m)+df[\u001b[33m'\u001b[39m\u001b[33mViz_Score\u001b[39m\u001b[33m'\u001b[39m].fillna(\u001b[32m0\u001b[39m)+df[\u001b[33m'\u001b[39m\u001b[33mSQL_Score\u001b[39m\u001b[33m'\u001b[39m].fillna(\u001b[32m0\u001b[39m)\n\u001b[32m     11\u001b[39m df\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m res = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTotal_score\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1189\u001b[39m maybe_callable = com.apply_if_callable(key, \u001b[38;5;28mself\u001b[39m.obj)\n\u001b[32m   1190\u001b[39m maybe_callable = \u001b[38;5;28mself\u001b[39m._check_deprecated_callable_usage(key, maybe_callable)\n\u001b[32m-> \u001b[39m\u001b[32m1191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexing.py:1431\u001b[39m, in \u001b[36m_LocIndexer._getitem_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1429\u001b[39m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[32m   1430\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_key(key, axis)\n\u001b[32m-> \u001b[39m\u001b[32m1431\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexing.py:1381\u001b[39m, in \u001b[36m_LocIndexer._get_label\u001b[39m\u001b[34m(self, label, axis)\u001b[39m\n\u001b[32m   1379\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: AxisInt):\n\u001b[32m   1380\u001b[39m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1381\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:4320\u001b[39m, in \u001b[36mNDFrame.xs\u001b[39m\u001b[34m(self, key, axis, level, drop_level)\u001b[39m\n\u001b[32m   4318\u001b[39m             new_index = index[loc]\n\u001b[32m   4319\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4320\u001b[39m     loc = \u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4322\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, np.ndarray):\n\u001b[32m   4323\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m loc.dtype == np.bool_:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:415\u001b[39m, in \u001b[36mRangeIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    413\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._range.index(new_key)\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[32m    417\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[31mKeyError\u001b[39m: np.float64(270.0)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {\n",
    "'CandID': ['C1', 'C2', 'C3', 'C4', 'C5'],\n",
    "'Batch': ['B1', 'B1', 'B2', 'B2', 'B3'],\n",
    "'DS_Score': [85, None, 78, 88, 90],\n",
    "'Viz_Score': [80, 75, 82, None, 88],\n",
    "'SQL_Score': [None, 70, 76, 85, 92]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df['Total_score'] = df['DS_Score'].fillna(0)+df['Viz_Score'].fillna(0)+df['SQL_Score'].fillna(0)\n",
    "df\n",
    "res = df.loc[df['Total_score'].max()]\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096db953",
   "metadata": {},
   "source": [
    "Q2 Solution 3: &emsp;&emsp;&emsp; df['DS_Score'].fillna(df['DS_Score'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b48dc9c",
   "metadata": {},
   "source": [
    "Q3 Solution 1: &emsp;&emsp;&emsp; select PurchaseID, BuyerID, net_amount from ( select (Amount-COALESCE(Discount,0) as net_amount from Purchases) as sub where net_amount=Amount-COALESCE(Discount,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfe3ee5",
   "metadata": {},
   "source": [
    "Q3 Solution 2: &emsp;&emsp;&emsp; total net revenue per BuyerID – \n",
    "select BuyerID, SUM(Amount) from Purchases group by BuyerID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c801f92",
   "metadata": {},
   "source": [
    "Q3 Solution 3: &emsp;&emsp;&emsp; if amount is NULL SQL will automatically treat it as 0 and do the aggregation on valid values. However still, the CASE WHEN THEN can be used to replace nulls with 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ab5b0c",
   "metadata": {},
   "source": [
    "Q4 Solution 1: &emsp;&emsp;&emsp; mean, var & max calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81b47a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.214285714285715\n",
      "1.7755102040816324\n",
      "22.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "readings = np.array ([18.0, 19.5, 21.0, 20.5, 19.0, 22.0, 21.5])\n",
    "print(readings.mean())\n",
    "print(readings.var())\n",
    "print(readings.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459cd7d4",
   "metadata": {},
   "source": [
    "Q4 Solution 2: &emsp;&emsp;&emsp; counting vals greater than 0.5+mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32e8abe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.214285714285715\n",
      "1.7755102040816324\n",
      "22.0\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "readings = np.array([18.0, 19.5, 21.0, 20.5, 19.0, 22.0, 21.5])\n",
    "print(readings.mean())\n",
    "print(readings.var())\n",
    "print(readings.max())\n",
    "print(np.size (readings [readings > (readings.mean()+0.5)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7b5d6c",
   "metadata": {},
   "source": [
    "Q4 Solution 3: &emsp;&emsp;&emsp; to exclude outliers, we can filter using below syntax\n",
    "readings[readings<100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eee4e383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.214285714285715\n",
      "1.7755102040816324\n",
      "22.0\n",
      "[18.  19.5 21.  20.5 19.  22.  21.5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "readings = np.array([18.0, 19.5, 21.0, 20.5, 19.0, 22.0, 21.5])\n",
    "print(readings.mean())\n",
    "print(readings.var())\n",
    "print(readings.max())\n",
    "print(readings [readings < 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e855f98c",
   "metadata": {},
   "source": [
    "# Section B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf6af6a",
   "metadata": {},
   "source": [
    "Q5 Solution 1: &emsp;&emsp;&emsp; the online channel in North grew from March-> Apr roughly by 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a0d473",
   "metadata": {},
   "source": [
    "![alt text](<Screenshot 2025-09-20 203914.png>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb14bd3",
   "metadata": {},
   "source": [
    "Q5 Solution 2: &emsp;&emsp;&emsp; DAX :: \n",
    "%Change = DIVIDE(GROUPBY(Sheet2,Sheet2[Month],Sheet2[Region]),SUM(Sheet2[Amount]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad79468",
   "metadata": {},
   "source": [
    "Q5 Solution 3: &emsp;&emsp;&emsp; If channel has few rows due to missing values, the last seen value can be pulled through"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6 Solution 1: &emsp;&emsp;&emsp; Avg satisfaction for churn yes / no"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52823f35",
   "metadata": {},
   "source": [
    "![alt text](<Screenshot 2025-09-20 205021.png>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dacb86d",
   "metadata": {},
   "source": [
    "Q6 Solution 2: &emsp;&emsp;&emsp; Yes using the below PowerBI ss it seems raising the ticket value has caused more churning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8e8c4c",
   "metadata": {},
   "source": [
    "![alt text](<Screenshot 2025-09-20 205210.png>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17b86a9",
   "metadata": {},
   "source": [
    "Q6 Solution 3: &emsp;&emsp;&emsp; If avg_response_time indicates delay in responding to customer’s query, I think, the churn rate would increase with increase in response time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cec1d71",
   "metadata": {},
   "source": [
    "Q7 Solution 1: &emsp;&emsp;&emsp; average payment per user\n",
    "select User, AVG(value) as average_payment_per_user from User_Payments group by User\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7 Solution 2: &emsp;&emsp;&emsp; max single payment\n",
    "select User, MAX(value) as max_single_payment from User_Payments group by User\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affab8ee",
   "metadata": {},
   "source": [
    "Q7 Solution 3: &emsp;&emsp;&emsp; if user’s row is missing it should be ignored as we’re not aware which UID it belongs to, and then mention it explicitly in documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6fbd8c",
   "metadata": {},
   "source": [
    "Q8 Solution 1: &emsp;&emsp;&emsp; work hours per Staff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58f27998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Staff</th>\n",
       "      <th>InTime</th>\n",
       "      <th>OutTime</th>\n",
       "      <th>TotalHrsWorked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S10</td>\n",
       "      <td>07:45</td>\n",
       "      <td>16:00</td>\n",
       "      <td>0 days 08:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>08:30</td>\n",
       "      <td>17:30</td>\n",
       "      <td>0 days 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S12</td>\n",
       "      <td>09:00</td>\n",
       "      <td>18:00</td>\n",
       "      <td>0 days 09:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Staff InTime OutTime  TotalHrsWorked\n",
       "0   S10  07:45   16:00 0 days 08:15:00\n",
       "1    11  08:30   17:30 0 days 09:00:00\n",
       "2   S12  09:00   18:00 0 days 09:00:00"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Staff': ['S10', '11', 'S12'],\n",
    "'InTime': ['07:45', '08:30', '09:00'],\n",
    "'OutTime': ['16:00', '17:30', '18:00']}\n",
    "df = pd.DataFrame(data)\n",
    "login = df['InTime']\n",
    "pd_login = pd.to_datetime(login, format='mixed')\n",
    "np_login = pd_login.to_numpy()\n",
    "\n",
    "logout = df['OutTime']\n",
    "pd_logout = pd.to_datetime(logout, format='mixed')\n",
    "np_logout = pd_logout.to_numpy()\n",
    "df['TotalHrsWorked'] = np_logout - np_login\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f430bff4",
   "metadata": {},
   "source": [
    "Q8 Solution 2: &emsp;&emsp;&emsp; staff ID S11 & S12 worked the longest by 45mins as of S10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657fc5ab",
   "metadata": {},
   "source": [
    "Q8 Solution 3: &emsp;&emsp;&emsp; "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
